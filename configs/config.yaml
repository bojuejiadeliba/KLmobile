---
lr: 0.001
min_lr: 0.000001
weight_decay: 0.0001
T_0: 500
train_batch_size: 16
val_batch_size: 32
clip_grad_val: 20.0
text_model_name: "lite_transformer"
text_model:
  num_embeddings: 49409
  padding_idx: 49408
  max_seq_length: 80
  embedding_dim: 256
  lr: 0.00001
  weight_decay: 0.0001

  transformer_encoder:
    num_heads: 8
    dropout_rate: 0.3

  lconv:
    num_heads: 8
    kernel_size: [15, 15, 31, 31, 31, 31, 63, 63, 63, 63, 63, 63]
    padding: "same"
    weight_softmax: True
    bias: False
    dropout_rate: 0.3

  n_blocks: 12
  output_dim: 512
  dropout_rate: 0.3
  last_layer_norm: False
  pos_encoding_dropout_rate: 0.1
  ffn_embedding_dim: 1024
  prior: False

image_model:
  model_name: "mobilenetv3_large"
  alpha: 1.0
  output_dim: 1280
  prior: True
  lr: 0.0001
  weight_decay: 0.0001

clip_model:
  proj_dim: 2048
  tau: 0.07
  dropout_rate: 0.3

convbert_model:
  num_attention_heads: 8
  num_hidden_layers: 512
  pretrained: true
  output_dim: 768
